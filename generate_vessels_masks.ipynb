{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path=''   # modify the dataset_path to your own dir\n",
    "assert dataset_path!='' and dataset_path!='/path/to/dataset/', 'Please specify the dataset_path!'\n",
    "\n",
    "path_photos = dataset_path+'Dataset indiano/'\n",
    "patch_size=48        # patch image size\n",
    "\n",
    "# load csv file\n",
    "df = pd.read_csv(dataset_path+'hbvalue.csv', sep=';')\n",
    "\n",
    "# cut the dataset only to indian dataset\n",
    "df = df[df['dataset']=='ind']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_normalized_single(imgs,mask):\n",
    "    imgs_normalized = np.empty(imgs.shape)\n",
    "    imgs_std = np.std(imgs)\n",
    "    imgs_mean = np.mean(imgs)\n",
    "    imgs_normalized = (imgs-imgs_mean)/imgs_std\n",
    "    for i in range(imgs.shape[2]):\n",
    "        imgs_normalized[:,:,i] = ((imgs_normalized[:,:,i] - np.min(imgs_normalized[:,:,i])) / (np.max(imgs_normalized[:,:,i])-np.min(imgs_normalized[:,:,i])))*255\n",
    "    return imgs_normalized\n",
    "\n",
    "\n",
    "# CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "#adaptive histogram equalization is used. In this, image is divided into small blocks called \"tiles\"\n",
    "# (tileSize is 8x8 by default in OpenCV). Then each of these blocks are histogram equalized as usual.\n",
    "#  So in a small area, histogram would confine to a small region (unless there is noise). \n",
    "# If noise is there, it will be amplified. To avoid this, contrast limiting is applied. \n",
    "# If any histogram bin is above the specified contrast limit (by default 40 in OpenCV),\n",
    "#  those pixels are clipped and distributed uniformly to other bins before applying histogram equalization.\n",
    "#  After equalization, to remove artifacts in tile borders, bilinear interpolation is applied\n",
    "def clahe_equalized_single(imgs):\n",
    "  clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8,8))\n",
    "  imgs_equalized = np.empty(imgs.shape)\n",
    "  for i in range(imgs.shape[2]):\n",
    "    imgs_equalized[:,:,i] = clahe.apply(np.array(imgs[:,:,i], dtype = np.uint8))\n",
    "  return imgs_equalized\n",
    "\n",
    "\n",
    "def adjust_gamma_single(imgs, gamma=1.0):\n",
    "  invGamma = 1.0 / gamma\n",
    "  table = np.array([((i / 255.0) ** invGamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "  # apply gamma correction using the lookup table\n",
    "  new_imgs = np.empty(imgs.shape)\n",
    "  for i in range(imgs.shape[2]):\n",
    "    new_imgs[:,:,i] = cv2.LUT(np.array(imgs[:,:,i], dtype = np.uint8), table)\n",
    "  return new_imgs\n",
    "\n",
    "def preprocess_single(image,mask):\n",
    "  \n",
    "  assert np.max(mask)==1\n",
    "  image=np.array(image)\n",
    "  image[:,:,0]=image[:,:,0]*mask\n",
    "  image[:,:,1]=image[:,:,1]*mask\n",
    "  image[:,:,2]=image[:,:,2]*mask\n",
    "\n",
    "  image=normal_normalized_single(image,mask)\n",
    "  image=clahe_equalized_single(image)\n",
    "  image=adjust_gamma_single(image,0.8)\n",
    "  image=image/255.0\n",
    "  return image\n",
    "\n",
    "\n",
    "def load_test_data(image):\n",
    "  #image=tf.image.decode_jpeg(image,channels=1)\n",
    "  #print(image.shape)\n",
    "  image=tf.image.resize(image,[patch_size,patch_size])\n",
    "  #image/=255.0\n",
    "  return image\n",
    "\n",
    "# pad images\n",
    "def padding_images(image,mask,stride):\n",
    "    h,w=image.shape[:2]\n",
    "    new_h,new_w=h,w\n",
    "    while (new_h-patch_size)%stride!=0:\n",
    "        new_h+=1\n",
    "    while (new_w-patch_size)%stride!=0:\n",
    "        new_w+=1\n",
    "    pad_image=np.zeros((new_h,new_w,3))\n",
    "    pad_image[:h,:w,:]=image\n",
    "    \n",
    "    pad_mask=np.zeros((new_h,new_w))\n",
    "    pad_mask[:h,:w]=mask\n",
    "    \n",
    "    return pad_image,pad_mask\n",
    "\n",
    "# images to patches\n",
    "def img2patch_list(image,stride=patch_size):\n",
    "    patch_list=[]\n",
    "    #image_binary=0.8*image[:,:,1:2]+0.2*image[:,:,2:3]  \n",
    "    for j in range(0,image.shape[1]-patch_size+1,stride):\n",
    "        for i in range(0,image.shape[0]-patch_size+1,stride):\n",
    "            patch=image[i:i+patch_size,j:j+patch_size,:]\n",
    "            patch_list.append(patch)\n",
    "    return patch_list\n",
    "\n",
    "# patches to image\n",
    "def patchlist2image(patch_list,stride,image_shape):\n",
    "    result=np.zeros(image_shape[:2])\n",
    "    sum_matrix=np.zeros(image_shape[:2])\n",
    "    index_x,index_y=0,0\n",
    "    for i in range(patch_list.shape[0]):\n",
    "        patch=patch_list[i,:,:,0]\n",
    "        #patch=np.where(patch>0.5,1,0)\n",
    "        #print(patch)\n",
    "        result[index_x:index_x+patch_size,index_y:index_y+patch_size]+=patch\n",
    "        sum_matrix[index_x:index_x+patch_size,index_y:index_y+patch_size]+=1\n",
    "        index_x+=stride\n",
    "        if index_x+patch_size>image_shape[0]:\n",
    "            index_x=0\n",
    "            index_y+=stride\n",
    "    return result/sum_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_unet= tf.keras.models.load_model(\"unet/pretrained_model\")\n",
    "stride=5\n",
    "\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "\n",
    "    # search folder\n",
    "    matching_folders = []\n",
    "    for folder_name in os.listdir(path_photos):\n",
    "        if folder_name.startswith(row['paziente'] + \"-\") and os.path.isdir(os.path.join(path_photos, folder_name)):\n",
    "            path_single_photo = os.path.join(path_photos, folder_name)\n",
    "\n",
    "            name_photo = folder_name.split(\"-\")[-1]\n",
    "\n",
    "            image_name=path_single_photo + \"/\" + name_photo + '_sclera.png'\n",
    "            \n",
    "            # load and process test images\n",
    "            image=plt.imread(image_name)\n",
    "            image[image[:, :, 3] == 0] = [0, 0, 0, 0]\n",
    "            image = cv2.resize(image, (500, 667))\n",
    "            original_shape=image.shape\n",
    "\n",
    "            # generate mask\n",
    "            mask = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            mask=np.where(mask>0,1,0)\n",
    "\n",
    "            image = image[:, :, :3]  # Rimuovi il canale alfa\n",
    "            # image to patches\n",
    "            image,pad_mask=padding_images(image,mask,stride)\n",
    "\n",
    "            image=preprocess_single(image,pad_mask)\n",
    "            test_patch_list=img2patch_list(image,stride)\n",
    "\n",
    "            # visualize the image\n",
    "            plt.figure(figsize=(8,8))\n",
    "            plt.title(image_name+\"-(\"+str(image.shape[0])+\",\"+str(image.shape[1])+\")\")\n",
    "            plt.imshow(image,cmap=plt.cm.gray)\n",
    "            plt.show()\n",
    "\n",
    "            # test dataloader\n",
    "            test_dataset=tf.data.Dataset.from_tensor_slices(test_patch_list)\n",
    "            test_dataset=test_dataset.map(load_test_data)\n",
    "            test_dataset=test_dataset.batch(64)\n",
    "            pred_result=[]\n",
    "            \n",
    "            # test process\n",
    "            for batch, patch in enumerate(test_dataset):\n",
    "                _,pred=model_unet(patch,training=False)\n",
    "                \n",
    "                pred=pred.numpy()\n",
    "                pred_result.append(pred)\n",
    "            pred_result=np.concatenate(pred_result,axis=0)\n",
    "            \n",
    "            # patches to image\n",
    "            print(\"post processing:\",image_name)\n",
    "            pred_image=patchlist2image(pred_result,stride,image.shape)\n",
    "            \n",
    "            pred_image=pred_image[:original_shape[0],:original_shape[1]]\n",
    "\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9, 9))\n",
    "            \n",
    "            mask = cv2.erode(mask.astype(np.uint8), kernel)\n",
    "\n",
    "            pred_image=pred_image*mask\n",
    "            pred_image=np.where(pred_image>0.5,1,0)\n",
    "                \n",
    "            # visualize the test result\n",
    "            plt.figure(figsize=(8,8))\n",
    "            plt.title(image_name+\"-(\"+str(image.shape[0])+\",\"+str(image.shape[1])+\")\")\n",
    "            plt.imshow(pred_image,cmap=plt.cm.gray)\n",
    "            plt.show()\n",
    "\n",
    "            plt.imsave(path_single_photo + \"/\" + name_photo + '_sclera_vessels_auto_deep.png',pred_image,cmap = plt.cm.gray)\n",
    "\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
